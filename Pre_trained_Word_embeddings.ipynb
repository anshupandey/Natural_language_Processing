{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Natural_language_Processing/blob/master/Pre_trained_Word_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDDJxLd1mJUF"
      },
      "source": [
        "# Pre-trained Word Embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5jyQdB3_mqTO"
      },
      "source": [
        "\n",
        "Natural Language Processing (NLP) has witnessed a massive surge in performance and usability thanks to **transfer learning**—a technique that allows models trained on large, general-purpose datasets to be adapted for specific tasks with minimal additional data and computational resources.\n",
        "\n",
        "**Word embeddings** lie at the heart of many modern NLP solutions. They transform raw text into numeric vectors (or “embeddings”) that capture semantic and syntactic relationships among words. By leveraging **pre-trained** embeddings, you tap into general language knowledge that has already been learned, saving time, computing power, and often boosting accuracy.\n",
        "\n",
        "---\n",
        "\n",
        "## What Is Transfer Learning?\n",
        "\n",
        "**Transfer learning** in NLP typically involves these steps:\n",
        "\n",
        "1. **Pre-training**: A large language model is trained on extensive text data (e.g., Wikipedia, Common Crawl). The model “learns” linguistic patterns such as syntax, semantics, and general context.  \n",
        "2. **Fine-tuning**: The pre-trained model is then adapted to a specific downstream task (like sentiment analysis, text classification, or named entity recognition) by adding specialized layers or re-training part of the network.\n",
        "\n",
        "In the context of **word embeddings**, transfer learning involves taking embeddings that have been learned on massive, general corpora and using them as a starting point for your own NLP tasks.\n",
        "\n",
        "---\n",
        "\n",
        "## Why Use Word Embeddings?\n",
        "\n",
        "Traditional NLP pipelines often relied on “bag-of-words” or “one-hot encoding” representations that only captured the presence or frequency of words without retaining word order or contextual nuance. Word embeddings overcame these limitations by providing:\n",
        "\n",
        "- **Dense, low-dimensional representations** (e.g., a 300-dimensional vector vs. a large one-hot vector).  \n",
        "- **Semantic relationships** (similar words have similar embedding vectors, enabling models to detect analogies and synonyms).  \n",
        "- **Reduced sparsity** (better generalization and less memory overhead than one-hot encodings).  \n",
        "\n",
        "By starting with **pre-trained word embeddings**, you get a strong language understanding “for free,” letting you focus on the downstream tasks that matter.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljcotrobmMhe"
      },
      "outputs": [],
      "source": [
        "!pip install gensim --quiet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuJ7_Hh_mO0J"
      },
      "source": [
        "## Word2vec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Iz2TS-nm8Lc"
      },
      "source": [
        "### Word2Vec\n",
        "\n",
        "**Word2Vec** (by Google) is one of the first widespread word embedding models. It comes in two flavors:\n",
        "- **CBOW (Continuous Bag of Words)**: Predicts a word based on its context.  \n",
        "- **Skip-gram**: Predicts the surrounding words given a target word.\n",
        "\n",
        "It generates embeddings by learning co-occurrence relationships over large corpora (e.g., Google News). Pre-trained Word2Vec embeddings are often 300-dimensional and remain popular for simpler NLP pipelines.\n",
        "\n",
        "**Pros**:\n",
        "- Easy to integrate.\n",
        "- Well-studied, with a large community of support.\n",
        "\n",
        "**Cons**:\n",
        "- Context-independent: The embedding for a word does not change based on surrounding words.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH4hEKuzmGmd",
        "outputId": "ef19eb55-1018-413e-da8c-52db158577d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n",
            "Vector for 'king': [ 0.12597656  0.02978516  0.00860596  0.13964844 -0.02563477 -0.03613281\n",
            "  0.11181641 -0.19824219  0.05126953  0.36328125]... (truncated)\n",
            "Similarity between 'king' and 'queen': 0.6511\n",
            "Top 5 words similar to 'king':\n",
            "  kings: 0.7138\n",
            "  queen: 0.6511\n",
            "  monarch: 0.6413\n",
            "  crown_prince: 0.6204\n",
            "  prince: 0.6160\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# 1. Load a pre-trained Word2Vec model\n",
        "#    This is the Google News 300-dim version (~1.6GB).\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")\n",
        "\n",
        "# 2. Generate word embedding for \"king\"\n",
        "king_vector = w2v_model[\"king\"]\n",
        "\n",
        "print(f\"Vector for 'king': {king_vector[:10]}... (truncated)\")\n",
        "\n",
        "# 3. Compute similarity between two words\n",
        "similarity_king_queen = w2v_model.similarity(\"king\", \"queen\")\n",
        "print(f\"Similarity between 'king' and 'queen': {similarity_king_queen:.4f}\")\n",
        "\n",
        "# 4. Find most similar words to \"king\"\n",
        "most_similar_to_king = w2v_model.most_similar(\"king\", topn=5)\n",
        "print(\"Top 5 words similar to 'king':\")\n",
        "for word, score in most_similar_to_king:\n",
        "    print(f\"  {word}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3KGmA8ImTAL"
      },
      "source": [
        "## GloVe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0a_DC_Cm_u_"
      },
      "source": [
        "\n",
        "### GloVe (Global Vectors)\n",
        "\n",
        "**GloVe** (by Stanford) is another widely-used method that mixes matrix factorization techniques with local context windows. Key differences from Word2Vec include the objective function’s focus on **global co-occurrence statistics**.\n",
        "\n",
        "**Pros**:\n",
        "- Captures both local and global context information.\n",
        "- Available pre-trained on Common Crawl and Wikipedia.\n",
        "\n",
        "**Cons**:\n",
        "- Similar context-independence limitation as Word2Vec.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sEu7mNebmStj",
        "outputId": "da973115-e872-48ea-b3e0-fbde379acc6d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "Vector for 'king': [-0.32307 -0.87616  0.21977  0.25268  0.22976  0.7388  -0.37954 -0.35307\n",
            " -0.84369 -1.1113 ]... (truncated)\n",
            "Similarity between 'king' and 'queen' (GloVe): 0.7508\n",
            "Top 5 words similar to 'king' (GloVe):\n",
            "  prince: 0.7682\n",
            "  queen: 0.7508\n",
            "  son: 0.7021\n",
            "  brother: 0.6986\n",
            "  monarch: 0.6978\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# 1. Load a pre-trained GloVe model\n",
        "#    Options: \"glove-wiki-gigaword-50\", \"glove-wiki-gigaword-100\",\n",
        "#    \"glove-wiki-gigaword-200\", \"glove-wiki-gigaword-300\"\n",
        "glove_model = api.load(\"glove-wiki-gigaword-100\")\n",
        "\n",
        "# 2. Generate word embedding for \"king\"\n",
        "king_vector_glove = glove_model[\"king\"]\n",
        "print(f\"Vector for 'king': {king_vector_glove[:10]}... (truncated)\")\n",
        "\n",
        "# 3. Compute similarity between two words\n",
        "similarity_king_queen_glove = glove_model.similarity(\"king\", \"queen\")\n",
        "print(f\"Similarity between 'king' and 'queen' (GloVe): {similarity_king_queen_glove:.4f}\")\n",
        "\n",
        "# 4. Find most similar words to \"king\"\n",
        "most_similar_to_king_glove = glove_model.most_similar(\"king\", topn=5)\n",
        "print(\"Top 5 words similar to 'king' (GloVe):\")\n",
        "for word, score in most_similar_to_king_glove:\n",
        "    print(f\"  {word}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6N3-5S3mWkp"
      },
      "source": [
        "## FastText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiLBR1iYnDEX"
      },
      "source": [
        "### FastText\n",
        "\n",
        "**FastText** (by Facebook AI Research) extends Word2Vec by learning embeddings for **subword units (n-grams)**. This means it can generate embeddings for out-of-vocabulary (OOV) words by composing subword embeddings.\n",
        "\n",
        "**Pros**:\n",
        "- Handles rare and unseen words better (due to subword information).\n",
        "- Often outperforms Word2Vec and GloVe on tasks involving morphologically rich languages.\n",
        "\n",
        "**Cons**:\n",
        "- More computationally intensive to train compared to standard Word2Vec.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RFu4mQfmQju",
        "outputId": "3ec2a468-3ee2-4294-88ce-09f691274079"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 958.5/958.4MB downloaded\n",
            "Vector for 'king': [-0.12063    0.0051695 -0.012447  -0.0078528 -0.023738  -0.082595\n",
            "  0.04579   -0.15382    0.06455    0.12893  ]... (truncated)\n",
            "Similarity between 'king' and 'queen' (FastText): 0.7704\n",
            "Top 5 words similar to 'king' (FastText):\n",
            "  king-: 0.7838\n",
            "  boy-king: 0.7705\n",
            "  queen: 0.7704\n",
            "  prince: 0.7701\n",
            "  kings: 0.7669\n"
          ]
        }
      ],
      "source": [
        "import gensim.downloader as api\n",
        "\n",
        "# 1. Load a pre-trained FastText model\n",
        "#    For instance, \"fasttext-wiki-news-subwords-300\"\n",
        "fasttext_model = api.load(\"fasttext-wiki-news-subwords-300\")\n",
        "\n",
        "# 2. Generate word embedding for \"king\"\n",
        "king_vector_fasttext = fasttext_model[\"king\"]\n",
        "print(f\"Vector for 'king': {king_vector_fasttext[:10]}... (truncated)\")\n",
        "\n",
        "# 3. Compute similarity between two words\n",
        "similarity_king_queen_fasttext = fasttext_model.similarity(\"king\", \"queen\")\n",
        "print(f\"Similarity between 'king' and 'queen' (FastText): {similarity_king_queen_fasttext:.4f}\")\n",
        "\n",
        "# 4. Find most similar words to \"king\"\n",
        "most_similar_to_king_fasttext = fasttext_model.most_similar(\"king\", topn=5)\n",
        "print(\"Top 5 words similar to 'king' (FastText):\")\n",
        "for word, score in most_similar_to_king_fasttext:\n",
        "    print(f\"  {word}: {score:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JgqgIujmZPp"
      },
      "source": [
        "## ELmo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxDSi_NxnF69"
      },
      "source": [
        "\n",
        "### ELMo (Embeddings from Language Models)\n",
        "\n",
        "**ELMo** (by the Allen Institute for AI) is an early model in the family of **contextual** word embeddings. ELMo:\n",
        "- Uses a bidirectional LSTM (biLSTM) trained on a language modeling objective.\n",
        "- Produces embeddings that vary according to the entire sentence context.\n",
        "\n",
        "**Pros**:\n",
        "- Context-sensitive embeddings, improving over static Word2Vec or GloVe vectors.\n",
        "- Marked improvement in many downstream tasks.\n",
        "\n",
        "**Cons**:\n",
        "- Larger model size and slower inference than static embeddings.\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVZ5TPf8mYNp",
        "outputId": "2cdf9dff-41ee-4cb6-ca46-e1a0db19912e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m248.2/248.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.3/77.3 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m594.2/594.2 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.1/103.1 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33mWARNING: The candidate selected for download or install is a yanked version: 'rich' candidate (version 12.1.0 at https://files.pythonhosted.org/packages/bc/be/1ace556afa0cf17599c2a631b04b280ae7502a9cf942c47fd66ca9ab5134/rich-12.1.0-py3-none-any.whl (from https://pypi.org/simple/rich/) (requires-python:>=3.6.2,<4.0.0))\n",
            "Reason for being yanked: Broken dependencies. Please upgrade to 12.2.0 or later\u001b[0m\u001b[33m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m729.8/729.8 kB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.8/229.8 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.4/119.4 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.5/163.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.9/294.9 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m750.6/750.6 MB\u001b[0m \u001b[31m592.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m897.5/897.5 kB\u001b[0m \u001b[31m36.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.1/51.1 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.3/47.3 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.0/126.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m659.5/659.5 kB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m70.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.7/211.7 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for fairscale (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "sqlalchemy 2.0.36 requires typing-extensions>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "accelerate 1.2.1 requires huggingface-hub>=0.21.0, but you have huggingface-hub 0.10.1 which is incompatible.\n",
            "albumentations 1.4.20 requires pydantic>=2.7.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "altair 5.5.0 requires typing-extensions>=4.10.0; python_version < \"3.14\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "bigframes 1.29.0 requires rich<14,>=12.4.4, but you have rich 12.1.0 which is incompatible.\n",
            "diffusers 0.31.0 requires huggingface-hub>=0.23.2, but you have huggingface-hub 0.10.1 which is incompatible.\n",
            "en-core-web-sm 3.7.1 requires spacy<3.8.0,>=3.7.2, but you have spacy 3.3.3 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.10 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-ai-generativelanguage 0.6.10 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.74.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery 3.25.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.27.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires google-api-core[grpc]<3.0.0dev,>=2.16.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-bigtable 2.27.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-datastore 2.20.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-firestore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-functions 1.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-iam 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-language 2.16.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-pubsub 2.27.1 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.0, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-pubsub 2.27.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-resource-manager 1.14.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1, but you have google-api-core 2.8.2 which is incompatible.\n",
            "google-cloud-translate 3.19.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-genai 0.3.0 requires pydantic<3.0.0dev,>=2.0.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpcio-status 1.62.3 requires protobuf>=4.21.6, but you have protobuf 3.20.0 which is incompatible.\n",
            "ibis-framework 9.2.0 requires rich<14,>=12.4.4, but you have rich 12.1.0 which is incompatible.\n",
            "langchain 0.3.12 requires pydantic<3.0.0,>=2.7.4, but you have pydantic 1.8.2 which is incompatible.\n",
            "langchain-core 0.3.25 requires pydantic<3.0.0,>=2.5.2; python_full_version < \"3.12.4\", but you have pydantic 1.8.2 which is incompatible.\n",
            "langchain-core 0.3.25 requires typing-extensions>=4.7, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "nibabel 5.3.2 requires typing-extensions>=4.6; python_version < \"3.13\", but you have typing-extensions 4.5.0 which is incompatible.\n",
            "openai 1.57.4 requires pydantic<3,>=1.9.0, but you have pydantic 1.8.2 which is incompatible.\n",
            "openai 1.57.4 requires typing-extensions<5,>=4.11, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pandas-gbq 0.25.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 2.8.2 which is incompatible.\n",
            "peft 0.14.0 requires huggingface-hub>=0.25.0, but you have huggingface-hub 0.10.1 which is incompatible.\n",
            "peft 0.14.0 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\n",
            "pydantic-core 2.27.1 requires typing-extensions!=4.7.0,>=4.6.0, but you have typing-extensions 4.5.0 which is incompatible.\n",
            "pymc 5.19.1 requires rich>=13.7.1, but you have rich 12.1.0 which is incompatible.\n",
            "pytensor 2.26.4 requires filelock>=3.15, but you have filelock 3.7.1 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires huggingface-hub>=0.20.0, but you have huggingface-hub 0.10.1 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.20.1 which is incompatible.\n",
            "tensorflow 2.17.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.13.1 requires protobuf<5,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "torchaudio 2.5.1+cu121 requires torch==2.5.1, but you have torch 1.11.0 which is incompatible.\n",
            "typeguard 4.4.1 requires typing-extensions>=4.10.0, but you have typing-extensions 4.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install allennlp==2.10.0 --quiet  # or any version compatible with your environment\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade accelerate huggingface_hub --quiet\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hdl36NBSGyrW",
        "outputId": "00254182-28c6-4b3c-9cb1-eb65cbcc4035"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/450.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m440.3/450.5 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m450.5/450.5 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cached-path 1.1.6 requires huggingface-hub<0.11.0,>=0.8.1, but you have huggingface-hub 0.27.0 which is incompatible.\n",
            "peft 0.14.0 requires torch>=1.13.0, but you have torch 1.11.0 which is incompatible.\n",
            "sentence-transformers 3.3.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.20.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 365
        },
        "id": "oBXYa_bLmg6y",
        "outputId": "74aefc99-76a5-4f93-cd2c-613c724d0f86"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "https://storage.googleapis.com/allennlp-public-models/elmo_2x4096_512_2048cnn_2xhighway_options.json",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-2cb97fce3e9f>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Create the ELMo embedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0melmo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_output_representations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 2. Prepare input text (tokenized)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, num_output_representations, requires_grad, do_layer_norm, dropout, vocab_to_cache, keep_sentence_boundaries, scalar_mix_parameters, module)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_elmo_lstm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             self._elmo_lstm = _ElmoBiLm(  # type: ignore\n\u001b[0m\u001b[1;32m    119\u001b[0m                 \u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                 \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, requires_grad, vocab_to_cache)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m         self._token_embedder = _ElmoCharacterEncoder(\n\u001b[0m\u001b[1;32m    511\u001b[0m             \u001b[0moptions_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/modules/elmo.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, options_file, weight_file, requires_grad)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptions_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_weight_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweight_file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/allennlp/common/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, extract_archive, force_extract)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \"\"\"\n\u001b[1;32m    133\u001b[0m     return str(\n\u001b[0;32m--> 134\u001b[0;31m         _cached_path.cached_path(\n\u001b[0m\u001b[1;32m    135\u001b[0m             \u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m             \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mCACHE_DIRECTORY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cached_path/_cached_path.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, extract_archive, force_extract, quiet, progress)\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mget_supported_schemes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mquiet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextract_archive\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mis_zipfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtarfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tarfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cached_path/_cached_path.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, quiet, progress)\u001b[0m\n\u001b[1;32m    282\u001b[0m     \u001b[0;31m# Get eTag to add to filename, if it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0metag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_etag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecoverable_errors\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0;31m# We might be offline, in which case we don't want to throw an error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cached_path/schemes/http.py\u001b[0m in \u001b[0;36mget_etag\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_etag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ETag\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cached_path/schemes/http.py\u001b[0m in \u001b[0;36mhead_response\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mMaxRetryError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mRecoverableServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreason\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_head_response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cached_path/schemes/http.py\u001b[0m in \u001b[0;36mvalidate_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidate_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m404\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mRECOVERABLE_SERVER_ERROR_CODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRecoverableServerError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: https://storage.googleapis.com/allennlp-public-models/elmo_2x4096_512_2048cnn_2xhighway_options.json"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "\n",
        "# 1. Define ELMo options: These configuration files and weight files are from the AllenNLP repository.\n",
        "options_file = \"https://storage.googleapis.com/allennlp-public-models/elmo_2x4096_512_2048cnn_2xhighway_options.json\"\n",
        "weight_file  = \"https://storage.googleapis.com/allennlp-public-models/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5\"\n",
        "\n",
        "# Create the ELMo embedder\n",
        "elmo = Elmo(options_file, weight_file, num_output_representations=1, dropout=0)\n",
        "\n",
        "# 2. Prepare input text (tokenized)\n",
        "sentence_1 = [\"The\", \"king\", \"loves\", \"his\", \"queen\"]\n",
        "sentence_2 = [\"The\", \"cat\", \"sat\", \"on\", \"the\", \"mat\"]\n",
        "sentences = [sentence_1, sentence_2]\n",
        "\n",
        "# 3. Convert tokens to character IDs\n",
        "character_ids = batch_to_ids(sentences)  # shape: (batch_size, sentence_length, max_word_length)\n",
        "\n",
        "# 4. Get ELMo embeddings\n",
        "elmo_embeddings = elmo(character_ids)  # returns a dict with 'elmo_representations' & 'mask'\n",
        "# elmo_embeddings[\"elmo_representations\"][0] is of shape: (batch_size, sentence_length, embedding_dim=1024)\n",
        "\n",
        "# Extract the representation for each token in each sentence\n",
        "rep_1 = elmo_embeddings[\"elmo_representations\"][0][0]  # embedding for sentence_1\n",
        "rep_2 = elmo_embeddings[\"elmo_representations\"][0][1]  # embedding for sentence_2\n",
        "\n",
        "# 5. Let's compare the vector for \"king\" in sentence_1 to \"queen\" in sentence_1\n",
        "#    \"king\" is at index 1, \"queen\" is at index 4\n",
        "king_vector_elmo = rep_1[1].detach().numpy()\n",
        "queen_vector_elmo = rep_1[4].detach().numpy()\n",
        "\n",
        "# 6. Similarity check (cosine similarity)\n",
        "def cosine_similarity(vec_a, vec_b):\n",
        "    dot = np.dot(vec_a, vec_b)\n",
        "    norm_a = np.linalg.norm(vec_a)\n",
        "    norm_b = np.linalg.norm(vec_b)\n",
        "    return dot / (norm_a * norm_b)\n",
        "\n",
        "similarity_king_queen_elmo = cosine_similarity(king_vector_elmo, queen_vector_elmo)\n",
        "print(f\"ELMo Cosine Similarity ('king' vs 'queen'): {similarity_king_queen_elmo:.4f}\")\n",
        "\n",
        "# Similarly, you could compare word embeddings across different sentences\n",
        "# to gauge semantic relatedness in context.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhUC5YNbnRRW"
      },
      "source": [
        "## 5. How to Use Pre-Trained Embeddings\n",
        "\n",
        "The process of integrating pre-trained embeddings into your NLP pipeline typically looks like this:\n",
        "\n",
        "1. **Download the Pre-Trained Embeddings**: Obtain the embeddings (e.g., `word2vec.300d.txt`, `glove.840B.300d.txt`) or use a framework like `gensim` for Word2Vec and GloVe, or `torchtext` for PyTorch.  \n",
        "2. **Load the Embeddings**: Use libraries such as `gensim` (for Word2Vec, GloVe, FastText) or `transformers` (for BERT/GPT).  \n",
        "3. **Embed Your Text**:  \n",
        "   - For static embeddings (Word2Vec, GloVe, FastText): Convert each word or token to its corresponding embedding vector.  \n",
        "   - For contextual embeddings (ELMo, BERT, GPT): Pass entire sentences through the model, and extract the embeddings from the model’s hidden layers.  \n",
        "4. **Integrate into Your Model**: These embeddings become the input features for downstream tasks like classification, question answering, or entity recognition.  \n",
        "\n",
        "---\n",
        "\n",
        "   \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "c77C1NCHnf6y"
      },
      "outputs": [],
      "source": [
        "!pip install gensim torch --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Ufs9U3r4n9Ga"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "vAiVlpzvn5tJ"
      },
      "outputs": [],
      "source": [
        "# Download Word2Vec embeddings trained on Google News\n",
        "w2v_model = api.load(\"word2vec-google-news-300\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "YGUVax1-n7ig"
      },
      "outputs": [],
      "source": [
        "# Provided Dataset is a list of text samples (site engineer notes) and their labels\n",
        "# Let's map the categories as follows:\n",
        "#   Critical -> 2\n",
        "#   Moderately Critical -> 1\n",
        "#   Non Critical -> 0\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/anshupandey/Natural_language_Processing/refs/heads/master/Data/telecom_site_notes_classification.csv\"\n",
        "data = pd.read_csv(url)\n",
        "texts = data['text']\n",
        "labels = data['label']\n",
        "classes = ['Non Crticial','Moderately Critical','Critical']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5yeTeZmQoAUJ"
      },
      "outputs": [],
      "source": [
        "def text_to_embedding(text):\n",
        "    tokens = text.lower().split()\n",
        "    valid_tokens = [token for token in tokens if token in w2v_model]\n",
        "    if not valid_tokens:\n",
        "        # Fallback to a zero vector if no token is recognized\n",
        "        return np.zeros(300)\n",
        "    # Average word embeddings\n",
        "    return np.mean([w2v_model[token] for token in valid_tokens], axis=0)\n",
        "\n",
        "X = np.array([text_to_embedding(t) for t in texts])\n",
        "y = np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding for 3 classes\n",
        "num_classes = 3\n",
        "y_onehot = np.zeros((len(y), num_classes))\n",
        "y_onehot[np.arange(len(y)), y] = 1\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42,stratify=y_onehot)\n"
      ],
      "metadata": {
        "id": "eKjh1yD72Jlr"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "WnxAq5AqoEoj"
      },
      "outputs": [],
      "source": [
        "# Define the model\n",
        "class Classifier(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_classes):\n",
        "        super(Classifier, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.fc1(x)\n",
        "        out = self.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "mbKwi4VkoKmS"
      },
      "outputs": [],
      "source": [
        "# Initialize the model, loss function, and optimizer\n",
        "input_size = 300\n",
        "hidden_size = 128  # You can adjust this\n",
        "model = Classifier(input_size, hidden_size, num_classes)\n",
        "criterion = nn.CrossEntropyLoss()  # Use CrossEntropyLoss for multi-class\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3_2glo1toNJ_",
        "outputId": "e48dce24-21bb-4218-d7ee-87dafa3d3e7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [10/100], Loss: 1.0386\n",
            "Epoch [20/100], Loss: 0.9405\n",
            "Epoch [30/100], Loss: 0.8081\n",
            "Epoch [40/100], Loss: 0.6533\n",
            "Epoch [50/100], Loss: 0.4978\n",
            "Epoch [60/100], Loss: 0.3621\n",
            "Epoch [70/100], Loss: 0.2565\n",
            "Epoch [80/100], Loss: 0.1808\n",
            "Epoch [90/100], Loss: 0.1291\n",
            "Epoch [100/100], Loss: 0.0946\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 100\n",
        "for epoch in range(num_epochs):\n",
        "  # Convert to tensors\n",
        "  inputs = torch.tensor(X_train, dtype=torch.float32)\n",
        "  labels = torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long) # Use argmax for class indices\n",
        "\n",
        "  # Forward pass\n",
        "  outputs = model(inputs)\n",
        "  loss = criterion(outputs, labels)\n",
        "\n",
        "  # Backward and optimize\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if (epoch+1) % 10 == 0:\n",
        "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Evaluation (add confusion matrix and classification report)\n",
        "with torch.no_grad():\n",
        "    inputs = torch.tensor(X_test, dtype=torch.float32)\n",
        "    outputs = model(inputs)\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    y_pred = predicted.numpy()\n",
        "    y_true = np.argmax(y_test, axis=1)\n",
        "    accuracy = accuracy_score(y_true, y_pred)\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(6, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "                xticklabels=classes, yticklabels=classes)\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.title(\"Confusion Matrix\")\n",
        "    plt.show()\n",
        "\n",
        "    # Classification Report\n",
        "    print(classification_report(y_true, y_pred, target_names=classes))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 606
        },
        "id": "nVcI-vIE2qNy",
        "outputId": "34ed8275-628f-47ec-91bc-dcb0901abbb1"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     precision    recall  f1-score   support\n",
            "\n",
            "       Non Crticial       1.00      1.00      1.00         2\n",
            "Moderately Critical       1.00      1.00      1.00         2\n",
            "           Critical       1.00      1.00      1.00         2\n",
            "\n",
            "           accuracy                           1.00         6\n",
            "          macro avg       1.00      1.00      1.00         6\n",
            "       weighted avg       1.00      1.00      1.00         6\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGe3ri2knVAH"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "**Transfer learning** with **pre-trained word embedding models** is a proven strategy for tackling a wide array of NLP tasks. By leveraging the linguistic knowledge captured in large-scale embeddings (whether static or contextual), you can drastically reduce training time and data requirements, often achieving higher accuracy.\n",
        "\n",
        "Whether you choose classic embeddings (Word2Vec, GloVe, FastText) or more advanced contextual models (ELMo, BERT, GPT), the principle remains the same: use pre-existing language understanding to give your task a jumpstart. As NLP continues to evolve, expect to see more specialized, powerful, and efficient models emerge, pushing the boundaries of what’s possible in text understanding and generation.\n",
        "\n",
        "**Happy coding, and may your embeddings capture all the right nuances!**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9ysvPehmtcu"
      },
      "source": [
        "### Further Reading & Resources\n",
        "\n",
        "- [Word2Vec Paper](https://arxiv.org/abs/1301.3781)  \n",
        "- [GloVe Paper](https://nlp.stanford.edu/pubs/glove.pdf)  \n",
        "- [FastText](https://fasttext.cc/)  \n",
        "- [ELMo Paper](https://arxiv.org/abs/1802.05365)  \n",
        "- [BERT Paper](https://arxiv.org/abs/1810.04805)  \n",
        "- [Hugging Face Transformers](https://github.com/huggingface/transformers)  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_DOOKevmtsu"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPtHb1zpj86LXCXr+f1QhM6",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}