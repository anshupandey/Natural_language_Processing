{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNggt57DguKAPLN+usia3kj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Natural_language_Processing/blob/master/TextGeneration_with_LSTM_Pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Text Generation with LSTM using Pytorch"
      ],
      "metadata": {
        "id": "ASWp9qbXb6bq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FyTHlkwzb52T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from collections import Counter\n",
        "from itertools import chain"
      ],
      "metadata": {
        "id": "kAJroH4xTK-F"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample Data\n",
        "data = \"The quick brown fox jumps over the lazy dog.\"\n",
        "\n",
        "# Tokenization and Vocabulary Creation\n",
        "words = data.split()\n",
        "vocab = list(set(words))\n",
        "word2idx = {word: idx for idx, word in enumerate(vocab)}\n",
        "idx2word = {idx: word for word, idx in word2idx.items()}\n",
        "vocab_size = len(vocab)\n",
        "sequences = [[word2idx[word] for word in words[:i + 1]] for i in range(1, len(words))]\n"
      ],
      "metadata": {
        "id": "WNKB4JVqTM_z"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Preparation\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, sequences):\n",
        "        self.sequences = sequences\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.sequences)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        sequence = self.sequences[idx]\n",
        "        return torch.tensor(sequence[:-1], dtype=torch.long), torch.tensor(sequence[-1], dtype=torch.long)\n"
      ],
      "metadata": {
        "id": "KFfbtG6ETOtU"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Model Definition\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        output, (hidden, cell) = self.lstm(embedded)\n",
        "        output = self.fc(output[:, -1, :])\n",
        "        return output"
      ],
      "metadata": {
        "id": "XN8P7SH8TQ8U"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7pDmT_ahTIO5"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "embedding_dim = 50\n",
        "hidden_dim = 100\n",
        "data_loader = DataLoader(TextDataset(sequences), batch_size=1, shuffle=True)\n",
        "\n",
        "# Training\n",
        "model = LSTMModel(vocab_size, embedding_dim, hidden_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(50):\n",
        "    for X, y in data_loader:\n",
        "        optimizer.zero_grad()\n",
        "        output = model(X)\n",
        "        loss = criterion(output, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction\n",
        "input_text = \"The quick brown\"\n",
        "input_seq = [word2idx[word] for word in input_text.split()]\n",
        "input_seq = torch.tensor(input_seq).unsqueeze(0)\n",
        "output = model(input_seq)\n",
        "predicted_word = idx2word[torch.argmax(output, dim=1).item()]\n",
        "print(predicted_word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kalGN-RVTUEk",
        "outputId": "f2bee42d-eb54-4b68-9905-110386d651cb"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fox\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchviz"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-Sg2Tn7UI8M",
        "outputId": "3096158d-0fae-4a44-814d-724da582bef0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchviz\n",
            "  Downloading torchviz-0.0.3-py3-none-any.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.5.1+cu121)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->torchviz) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (3.0.2)\n",
            "Downloading torchviz-0.0.3-py3-none-any.whl (5.7 kB)\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from torchviz import make_dot\n",
        "# Display Model Architecture using torchviz\n",
        "X, y = next(iter(data_loader))\n",
        "output = model(X)\n",
        "make_dot(output, params=dict(model.named_parameters())).render(\"model_arch\", format=\"png\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "PrQAZCb6TZTS",
        "outputId": "0c48c4eb-715f-4a2f-9652-22aefbbc8721"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'model_arch.png'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1DjdW4juUG-c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}