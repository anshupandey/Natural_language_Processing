{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GPT2_using_huggingface_API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anshupandey/Natural_language_Processing/blob/master/NLP%20-%20Transfer%20Learning/GPT2_using_huggingface_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEKzqI4YmzKe"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTcl4K5hmn6E"
      },
      "source": [
        "from transformers import GPT2Tokenizer\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\") #gpt2-medium, gpt-large\n",
        "tokenizer(\"Hello world\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ISJpxRKNKhkn"
      },
      "source": [
        "tokenizer(\"Hello world\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rquHu5T2KkKG"
      },
      "source": [
        "tokenizer(\" Hello world\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oNWgQg5muHX"
      },
      "source": [
        "tokenizer(\" Hello world my name is anshu\")['input_ids']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AckkdihFzzd_"
      },
      "source": [
        "import tensorflow.python.ops.numpy_ops.np_config\n",
        "from tensorflow.python.ops.numpy_ops import np_config\n",
        "np_config.enable_numpy_behavior()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmJ41rBd1AOQ"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ZdTnfrMzgU-",
        "outputId": "86e1798e-3e0f-4ab0-a30c-cb0684df67e0"
      },
      "source": [
        "from transformers import GPT2Model\n",
        "model = GPT2Model.from_pretrained('gpt2')\n",
        "# gpt2 = 12 layers - 768 dimensional vector\n",
        "# gpt2-medium = 24 layers - 1024 dimensional vector\n",
        "# gpt2-large = 36 layers - 1280 dimensional vector\n",
        "\n",
        "inputs = tokenizer(\"hi, my dog is cute, how are you\", return_tensors=\"pt\")['input_ids']\n",
        "print(inputs)\n",
        "outputs = model(inputs)\n",
        "\n",
        "last_hidden_states = outputs.last_hidden_state\n",
        "\n",
        "last_hidden_states.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 5303,    11,   616,  3290,   318, 13779,    11,   703,   389,   345]])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 10, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8FK88lU2w9P",
        "outputId": "c9cb3d15-a98d-4b49-9817-caa53830e3c0"
      },
      "source": [
        "inputs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 5303,    11,   616,  3290,   318, 13779,    11,   703,   389,   345]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twwufg6i0tee",
        "outputId": "7aa9efff-c7c5-4da7-da61-d725d9d24105"
      },
      "source": [
        "last_hidden_states.cpu().detach().numpy().shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zq9XLGZL4i_O",
        "outputId": "ef9bbe0c-c67c-472f-8766-03180bc788cb"
      },
      "source": [
        "# get sentence vectorization - take the vector of the last token = equivalent to sentence tokenization\n",
        "last_hidden_states.cpu().detach().numpy()[0,-1,:].shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(768,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CL4spVAmzMmy"
      },
      "source": [
        "def doc2vec(doc):\n",
        "  inputs = tokenizer(doc, return_tensors=\"pt\")['input_ids']\n",
        "  outputs = model(inputs)\n",
        "  last_hidden_states = outputs.last_hidden_state\n",
        "  vec = last_hidden_states.cpu().detach().numpy()[0,-1,:]\n",
        "  vec = vec.reshape(-1,768)\n",
        "  return vec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9kX6bwsOcvp"
      },
      "source": [
        "doc1 = \"Hi, the world looks more wonderful today.\"\n",
        "doc2 = \"Hello, it looks like the world is more beautiful today.\"\n",
        "vec1 = doc2vec(doc1)\n",
        "vec2 = doc2vec(doc2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uG6HME8HO7ms",
        "outputId": "b7f4a5a8-4bc6-4d79-fff1-0f8c288f8693",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vec1.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 768)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dlu_yrrOxO_"
      },
      "source": [
        "from sklearn import metrics"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCXa1eMPO0Dd",
        "outputId": "50153899-fae8-423a-f37e-48269db6046f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "metrics.pairwise.cosine_similarity(vec1,vec2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9998337]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsDyE3_VO5D2",
        "outputId": "7e0ffbbd-31fd-4248-852c-bec93d76c576",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc1 = \"Hi, the world looks more wonderful today, i love such amazing days and its beautiful.\"\n",
        "doc2 = \"john bought a watch and it was costly, bad and he disliked that watch which was black in color and dirty\"\n",
        "vec1 = doc2vec(doc1)\n",
        "vec2 = doc2vec(doc2)\n",
        "metrics.pairwise.cosine_similarity(vec1,vec2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.98882776]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Text Generation with GPT"
      ],
      "metadata": {
        "id": "hkJMRq-8Csan"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouTwu33MPtZS"
      },
      "source": [
        "from transformers import pipeline\n",
        "gpt_generator = pipeline('text-generation',model='gpt2')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"Python is beautiful\""
      ],
      "metadata": {
        "id": "LzMHPC1ZC4A6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = gpt_generator(doc,do_sample=True,top_k=50,max_length=128,num_return_sequences=5)\n",
        "\n",
        "for sent in sentences:\n",
        "  print(sent['generated_text'])\n",
        "  print(\"************************************************\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JzjDL4PDBLw",
        "outputId": "30131c12-1961-4db6-dd7a-eda0415ba2be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python is beautiful to use, especially in an interview environment but not all of a sudden you have to create a complex API. Even this way you are always left with using the API itself.\n",
            "\n",
            "The main issue that we can overcome is to keep the data short and clean to prevent accidental corruption of the data structure and to make clean API calls with an interface that is very easy to understand and understood by beginners. Because of that, I think I can recommend the tutorial by Robert Littman called \"The Power of Python\" (pdf, 539kB).\n",
            "\n",
            "The basic way to get acquainted with Python is by working as an\n",
            "************************************************\n",
            "Python is beautiful. It's also perfect for working with an API that you just have to know how to implement.\n",
            "\n",
            "CocoaPods is another gem that I haven't used for quite a while, but that was so awesome so when I wrote it I did it. Because you can still build your own.\n",
            "\n",
            "So, I've got this tutorial for you. It's a quick demonstration of what it does best.\n",
            "\n",
            "In case you'd never known, CocoaPod is a wrapper around PHP that allows you to add your own classes, and use them. The only problem here, CocoaPod doesn't\n",
            "************************************************\n",
            "Python is beautiful to use. So let's break it down, using this basic logic:\n",
            "\n",
            "The first command is to run C# on your project's C# application. This is the C# version you're editing. In other words, just run: C# --stdin=c#1.0.0.0 | C# --stdout=c#1.1.1.0.0 --stdin=c#1.6.1.0.0\n",
            "\n",
            "Using this in C# and other compilers makes this pretty:\n",
            "\n",
            "$ git submodule update-git-submodule\n",
            "************************************************\n",
            "Python is beautiful, a few new features, and a small amount of bugs. The last three were in one of the packages we provided.\n",
            "\n",
            "You are going to want to have to get acquainted with the project and build a better application.\n",
            "\n",
            "Building a project\n",
            "\n",
            "Now to build a.NET application\n",
            "\n",
            "I'm used to developing on Github and GitHub, so this article is going to give you a look at how we built our project.\n",
            "\n",
            "Let's see how our project structure can be simplified (right now we are just using a single name).\n",
            "\n",
            "We are going to use a simple name:\n",
            "\n",
            "\n",
            "************************************************\n",
            "Python is beautiful.\n",
            "\n",
            "The main downside of the package, is that it is complex, with more than four thousand options and is expensive and time consuming. Nevertheless this version of the system was one of the last things I did as code reviewer. It's free and there is plenty of room for improvement in any future projects.\n",
            "\n",
            "It is not available all at once, so your contribution can be easily delivered to your system. It is also easy to read and read without any hassle.\n",
            "\n",
            "When making the project, always consider how to use the available documentation.\n",
            "\n",
            "All of this is part of the release of the system\n",
            "************************************************\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc = \"\"\"\n",
        "imort matplotlib.pyplot as plt\n",
        "\n",
        "image = 'image.jpg'\n",
        "\n",
        "# load the image\n",
        "\"\"\"\n",
        "\n",
        "print(gpt_generator(doc,do_sample=True,top_k=10,max_length=256,temperature=1)[0]['generated_text'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRRRA1umDYzb",
        "outputId": "cbb0b06a-9248-4efc-a29e-0cafb41db429"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "imort matplotlib.pyplot as plt\n",
            "\n",
            "image = 'image.jpg'\n",
            "\n",
            "# load the image\n",
            "\n",
            "if image =='svg' :\n",
            "\n",
            "image = 'img/v1.jpg'\n",
            ".append(image, 'png/v1.png')\n",
            "\n",
            "# create a new image\n",
            "\n",
            "from plt.image import Image\n",
            "\n",
            "from plt.utils import get_raw_data\n",
            "\n",
            "from plt.utils import get_image_data as img\n",
            "\n",
            "from plt.utils.pyplot import x,y\n",
            "\n",
            "if img == None :\n",
            "\n",
            "x = x[ 0 ].replace('/ ','\\t')\n",
            "\n",
            "y = y[ 0 ].replace('/ ','\\t')\n",
            "\n",
            "# load the img\n",
            "\n",
            "if image =='svg' :\n",
            "\n",
            "image = 'img/v1.gif'\n",
            "\n",
            ".append(image, 'png/v1.png')\n",
            "\n",
            "# load the img\n",
            "\n",
            "#\n",
            "\n",
            "# load the data from\n",
            "\n",
            "from plt.image import Image\n",
            "\n",
            "from plt.utils import get_raw_data as img\n",
            "\n",
            "from plt.util\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YPDEBnhbERoO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}